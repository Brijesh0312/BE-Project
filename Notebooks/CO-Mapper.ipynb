{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "587a0b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CO2:write python program implement link list datum structure', 'CO2:time complexity quicksort algorithm', 'CO3:communicate technical concept non technical audience']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Define the course outcomes and questions\n",
    "course_outcomes = ['By the end of this course, students should be able to design and develop software applications using modern software engineering techniques',\n",
    "                    'Students should be able to analyze and evaluate algorithms and data structures',\n",
    "                    'Students should be able to communicate effectively and collaborate in team settings']\n",
    "\n",
    "questions = ['Write a Python program to implement a linked list data structure',\n",
    "            'What is the time complexity of the quicksort algorithm?',\n",
    "            'How would you communicate a technical concept to a non-technical audience?']\n",
    "\n",
    "# Load the NLP model and add the course outcomes and questions to the nlp pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the course outcomes and questions\n",
    "course_outcomes = [preprocess(outcome) for outcome in course_outcomes]\n",
    "questions = [preprocess(question) for question in questions]\n",
    "\n",
    "# Define a function to extract keywords\n",
    "def extract_keywords(text, nlp, max_keywords=10, min_token_freq=2, min_keyword_len=2):\n",
    "    doc = nlp(text)\n",
    "    # Get the frequency of each token and its lemma in the document\n",
    "    freq = {}\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space:\n",
    "            for form in (token.lemma_, token.text):\n",
    "                if form not in freq:\n",
    "                    freq[form] = 0\n",
    "                freq[form] += 1\n",
    "    # Sort the tokens by frequency\n",
    "    sorted_tokens = sorted(freq, key=freq.get, reverse=True)\n",
    "    # Extract the keywords based on the sorted tokens\n",
    "    keywords = []\n",
    "    for token in sorted_tokens:\n",
    "        if len(token) < min_keyword_len:\n",
    "            continue\n",
    "        if freq[token] < min_token_freq or len(keywords) >= max_keywords:\n",
    "            break\n",
    "        keywords.append(token)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def map_questions_to_outcomes(course_outcomes, questions, nlp, max_keywords=10, min_token_freq=2, min_keyword_len=2):\n",
    "    # Preprocess the course outcomes and questions\n",
    "    course_outcomes = [preprocess(outcome) for outcome in course_outcomes]\n",
    "    questions = [preprocess(question) for question in questions]\n",
    "    # Extract the keywords for each course outcome\n",
    "    keywords = {}\n",
    "    for i, outcome in enumerate(course_outcomes):\n",
    "        keywords[f'CO{i+1}'] = extract_keywords(outcome, nlp, max_keywords, min_token_freq, min_keyword_len)\n",
    "    # Create a PhraseMatcher for each course outcome\n",
    "    matchers = {}\n",
    "    for key in keywords:\n",
    "        matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "        patterns = [nlp(keyword) for keyword in keywords[key]]\n",
    "        matcher.add(key, None, *patterns)\n",
    "        matchers[key] = matcher\n",
    "    # Match the keywords from the course outcomes to the questions\n",
    "    mapped_questions = []\n",
    "    for question in questions:\n",
    "        question_doc = nlp(question)\n",
    "        for key in matchers:\n",
    "            matches = matchers[key](question_doc)\n",
    "            if matches:\n",
    "                mapped_questions.append(f\"{key}:{question}\")\n",
    "    return mapped_questions\n",
    "\n",
    "    \n",
    "\n",
    "mapped_questions = map_questions_to_outcomes(course_outcomes, questions, nlp)\n",
    "\n",
    "print(mapped_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca970e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc44be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
