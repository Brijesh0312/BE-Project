{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "587a0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy import displacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "def CourseOutcomes(question,course_outcomes):\n",
    "\n",
    "\n",
    "\n",
    "# Load the NLP model and add the course outcomes and questions to the nlp pipeline\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "    def preprocess(text):\n",
    "        doc = nlp(text)\n",
    "        tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the course outcomes and questions\n",
    "    course_outcomes = [preprocess(outcome) for outcome in course_outcomes]\n",
    "    Questions = preprocess(question)\n",
    "\n",
    "# Define a function to extract keywords\n",
    "    def extract_keywords(text, nlp, max_keywords=10, min_token_freq=2, min_keyword_len=2):\n",
    "        doc = nlp(text)\n",
    "    # Get the frequency of each token and its lemma in the document\n",
    "        freq = {}\n",
    "        for token in doc:\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space:\n",
    "                for form in (token.lemma_, token.text):\n",
    "                    if form not in freq:\n",
    "                        freq[form] = 0\n",
    "                    freq[form] += 1\n",
    "    # Sort the tokens by frequency\n",
    "        sorted_tokens = sorted(freq, key=freq.get, reverse=True)\n",
    "    # Extract the keywords based on the sorted tokens\n",
    "        keywords = []\n",
    "        for token in sorted_tokens:\n",
    "            if len(token) < min_keyword_len:\n",
    "                continue\n",
    "            if freq[token] < min_token_freq or len(keywords) >= max_keywords:\n",
    "                break\n",
    "            keywords.append(token)\n",
    "        return keywords\n",
    "\n",
    "\n",
    "    def map_questions_to_outcomes(course_outcomes, question, nlp, max_keywords=10, min_token_freq=2, min_keyword_len=2):\n",
    "        # Preprocess the course outcomes and questions\n",
    "        course_outcomes = [preprocess(outcome) for outcome in course_outcomes]\n",
    "        question = preprocess(question) \n",
    "    # Extract the keywords for each course outcome\n",
    "        keywords = {}\n",
    "        for i, outcome in enumerate(course_outcomes):\n",
    "            keywords[f'CO{i+1}'] = extract_keywords(outcome, nlp, max_keywords, min_token_freq, min_keyword_len)\n",
    "    # Create a PhraseMatcher for each course outcome\n",
    "        matchers = {}\n",
    "        for key in keywords:\n",
    "            matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "            patterns = [nlp(keyword) for keyword in keywords[key]]\n",
    "            matcher.add(key, None, *patterns)\n",
    "            matchers[key] = matcher\n",
    "    # Match the keywords from the course outcomes to the questions\n",
    "        \n",
    "        question_doc = nlp(question)\n",
    "        outcome=None\n",
    "        for key in matchers:\n",
    "                matches = matchers[key](question_doc)\n",
    "                if matches:\n",
    "                   outcome=key\n",
    "                   break\n",
    "        return outcome\n",
    "\n",
    "    \n",
    "   \n",
    "    mapped_question = map_questions_to_outcomes(course_outcomes, question, nlp)\n",
    "        \n",
    "    return mapped_question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_blooms_level(question,blooms_verbs):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(question)\n",
    "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
    "    for level, bloom_verbs in blooms_verbs.items():\n",
    "        if any(verb in bloom_verbs for verb in verbs):\n",
    "            return level\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fdd092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Write a Python program to implement a linked list data structure': {'Blooms_level': 'Applying', 'CO': 'CO2'}, 'What is the time complexity of the quicksort algorithm?': {'Blooms_level': None, 'CO': 'CO2'}, 'How would you communicate a technical concept to a non-technical audience?': {'Blooms_level': None, 'CO': 'CO3'}}\n"
     ]
    }
   ],
   "source": [
    "def Mapper(questions,course_outcomes):\n",
    "    blooms_verbs = {\n",
    "    'Remembering': ['define', 'list', 'name', 'recall', 'recognize'],\n",
    "    'Understanding': ['explain', 'interpret', 'summarize', 'classify', 'compare'],\n",
    "    'Applying': ['apply', 'solve', 'use', 'demonstrate', 'modify','implement'],\n",
    "    'Analyzing': ['analyze', 'compare', 'differentiate', 'organize', 'categorize'],\n",
    "    'Evaluating': ['evaluate', 'judge', 'assess', 'critique', 'justify'],\n",
    "    'Creating': ['create', 'design', 'develop', 'synthesize', 'construct']\n",
    "    }\n",
    "    mapper={}\n",
    "    for question in questions:\n",
    "        bloom=identify_blooms_level(question,blooms_verbs)\n",
    "        Question_local=question\n",
    "        CO=CourseOutcomes(Question_local,course_outcomes)\n",
    "        temp={\n",
    "            \"Blooms_level\":bloom,\n",
    "            \"CO\":CO\n",
    "        }\n",
    "        mapper[question]=temp\n",
    "    return mapper\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
